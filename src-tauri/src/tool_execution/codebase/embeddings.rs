//! å‘é‡åŒ–æ¨¡å—
//!
//! è°ƒç”¨ OpenAI API å°†ä»£ç å—è½¬æ¢ä¸ºå‘é‡

use super::chunking::CodeChunk;
use reqwest::Client;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::time::{Duration, Instant};
use tokio::time::sleep;

/// å¸¦å‘é‡çš„ä»£ç å—
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EmbeddedChunk {
    /// åŸå§‹ chunk
    pub chunk: CodeChunk,

    /// å‘é‡ï¼ˆ1536 ç»´ï¼‰
    pub embedding: Vec<f32>,
}

/// Embedding ç»Ÿè®¡ä¿¡æ¯
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EmbeddingStats {
    /// æ€»å…±å¤„ç†çš„ chunk æ•°é‡
    pub total_chunks: usize,

    /// æ€»å…±æ¶ˆè€—çš„ tokens
    pub total_tokens: usize,

    /// é¢„ä¼°æˆæœ¬ï¼ˆç¾å…ƒï¼‰
    pub estimated_cost: f64,

    /// ç¼“å­˜å‘½ä¸­æ¬¡æ•°
    pub cache_hits: usize,

    /// API è°ƒç”¨æ¬¡æ•°
    pub api_calls: usize,

    /// è€—æ—¶ï¼ˆç§’ï¼‰
    pub duration_secs: f64,
}

/// OpenAI API è¯·æ±‚
#[derive(Serialize)]
struct EmbeddingRequest {
    model: String,
    input: Vec<String>,
    encoding_format: String,
}

/// OpenAI API å“åº”
#[derive(Deserialize)]
struct EmbeddingResponse {
    data: Vec<EmbeddingData>,
    usage: Usage,
}

#[derive(Deserialize)]
struct EmbeddingData {
    embedding: Vec<f32>,
    index: usize,
}

#[derive(Deserialize)]
struct Usage {
    total_tokens: usize,
}

/// Embeddings å®¢æˆ·ç«¯
pub struct EmbeddingsClient {
    api_key: String,
    client: Client,
    model: String,
    batch_size: usize,
    cache: HashMap<String, Vec<f32>>, // ç®€å•çš„å†…å­˜ç¼“å­˜
}

impl EmbeddingsClient {
    /// åˆ›å»ºå®¢æˆ·ç«¯
    pub fn new(api_key: String) -> Self {
        Self {
            api_key,
            client: Client::builder()
                .timeout(Duration::from_secs(60))
                .build()
                .unwrap(),
            model: "text-embedding-3-small".to_string(),
            batch_size: 100, // OpenAI æœ€å¤šæ”¯æŒ 2048ï¼Œä½†æˆ‘ä»¬ç”¨ 100 æ›´ç¨³å®š
            cache: HashMap::new(),
        }
    }

    /// ä¸ºå•ä¸ª chunk ç”Ÿæˆå‘é‡
    pub async fn embed_chunk(
        &mut self,
        chunk: &CodeChunk,
    ) -> Result<EmbeddedChunk, Box<dyn std::error::Error>> {
        // æ£€æŸ¥ç¼“å­˜
        let cache_key = self.compute_cache_key(&chunk.embedding_text);
        if let Some(embedding) = self.cache.get(&cache_key) {
            return Ok(EmbeddedChunk {
                chunk: chunk.clone(),
                embedding: embedding.clone(),
            });
        }

        // è°ƒç”¨ API
        let (embeddings, _tokens) = self.call_api(vec![chunk.embedding_text.clone()]).await?;

        // æ›´æ–°ç¼“å­˜
        if let Some(embedding) = embeddings.first() {
            self.cache.insert(cache_key, embedding.clone());

            Ok(EmbeddedChunk {
                chunk: chunk.clone(),
                embedding: embedding.clone(),
            })
        } else {
            Err("No embedding returned".into())
        }
    }

    /// æ‰¹é‡ç”Ÿæˆå‘é‡ï¼ˆæ¨èä½¿ç”¨ï¼‰
    pub async fn embed_chunks(
        &mut self,
        chunks: Vec<CodeChunk>,
    ) -> Result<(Vec<EmbeddedChunk>, EmbeddingStats), Box<dyn std::error::Error>> {
        let start_time = Instant::now();
        let mut embedded_chunks = Vec::new();
        let mut stats = EmbeddingStats {
            total_chunks: chunks.len(),
            total_tokens: 0,
            estimated_cost: 0.0,
            cache_hits: 0,
            api_calls: 0,
            duration_secs: 0.0,
        };

        // åˆ†æ‰¹å¤„ç†
        for batch in chunks.chunks(self.batch_size) {
            println!("ğŸ§  å¤„ç†æ‰¹æ¬¡ ({} chunks)...", batch.len());

            // åˆ†ç¦»ç¼“å­˜å‘½ä¸­å’Œéœ€è¦è°ƒç”¨ API çš„
            let mut texts_to_embed = Vec::new();
            let mut indices_to_embed = Vec::new();

            for (idx, chunk) in batch.iter().enumerate() {
                let cache_key = self.compute_cache_key(&chunk.embedding_text);

                if let Some(embedding) = self.cache.get(&cache_key) {
                    // ç¼“å­˜å‘½ä¸­
                    embedded_chunks.push(EmbeddedChunk {
                        chunk: chunk.clone(),
                        embedding: embedding.clone(),
                    });
                    stats.cache_hits += 1;
                } else {
                    // éœ€è¦è°ƒç”¨ API
                    texts_to_embed.push(chunk.embedding_text.clone());
                    indices_to_embed.push(idx);
                }
            }

            // è°ƒç”¨ API
            if !texts_to_embed.is_empty() {
                match self.call_api_with_retry(texts_to_embed.clone()).await {
                    Ok((embeddings, tokens)) => {
                        // æ›´æ–°ç»Ÿè®¡
                        stats.api_calls += 1;
                        stats.total_tokens += tokens;
                        stats.estimated_cost += (tokens as f64 / 1000.0) * 0.00002;

                        // ä¿å­˜ç»“æœ
                        for (i, embedding) in embeddings.iter().enumerate() {
                            let chunk_idx = indices_to_embed[i];
                            let chunk = &batch[chunk_idx];

                            // æ›´æ–°ç¼“å­˜
                            let cache_key = self.compute_cache_key(&chunk.embedding_text);
                            self.cache.insert(cache_key, embedding.clone());

                            // æ·»åŠ åˆ°ç»“æœ
                            embedded_chunks.push(EmbeddedChunk {
                                chunk: chunk.clone(),
                                embedding: embedding.clone(),
                            });
                        }
                    }
                    Err(e) => {
                        eprintln!("âŒ API è°ƒç”¨å¤±è´¥: {}", e);
                        // ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹
                    }
                }

                // é¿å…è§¦å‘é€Ÿç‡é™åˆ¶
                sleep(Duration::from_millis(200)).await;
            }

            // æ‰“å°è¿›åº¦
            let progress = (embedded_chunks.len() as f64 / chunks.len() as f64) * 100.0;
            println!(
                "ğŸ“Š è¿›åº¦: {:.1}% ({}/{})",
                progress,
                embedded_chunks.len(),
                chunks.len()
            );
        }

        stats.duration_secs = start_time.elapsed().as_secs_f64();

        println!("\nâœ… å‘é‡åŒ–å®Œæˆ!");
        println!("  æ€»æ•°: {} chunks", stats.total_chunks);
        println!("  ç¼“å­˜å‘½ä¸­: {}", stats.cache_hits);
        println!("  API è°ƒç”¨: {}", stats.api_calls);
        println!("  æ€» tokens: {}", stats.total_tokens);
        println!("  é¢„ä¼°æˆæœ¬: ${:.4}", stats.estimated_cost);
        println!("  è€—æ—¶: {:.2}s", stats.duration_secs);

        Ok((embedded_chunks, stats))
    }

    /// è°ƒç”¨ OpenAI APIï¼ˆå¸¦é‡è¯•ï¼‰
    async fn call_api_with_retry(
        &self,
        texts: Vec<String>,
    ) -> Result<(Vec<Vec<f32>>, usize), Box<dyn std::error::Error>> {
        let max_retries = 3;
        let mut last_error = None;

        for attempt in 1..=max_retries {
            match self.call_api(texts.clone()).await {
                Ok(result) => return Ok(result),
                Err(e) => {
                    eprintln!("âš ï¸ API è°ƒç”¨å¤±è´¥ (å°è¯• {}/{}): {}", attempt, max_retries, e);
                    last_error = Some(e);

                    // æŒ‡æ•°é€€é¿
                    let delay = Duration::from_secs(2u64.pow(attempt as u32));
                    sleep(delay).await;
                }
            }
        }

        Err(last_error.unwrap_or_else(|| "Unknown error".into()))
    }

    /// è°ƒç”¨ OpenAI APIï¼ˆå•æ¬¡ï¼‰
    async fn call_api(
        &self,
        texts: Vec<String>,
    ) -> Result<(Vec<Vec<f32>>, usize), Box<dyn std::error::Error>> {
        let request = EmbeddingRequest {
            model: self.model.clone(),
            input: texts,
            encoding_format: "float".to_string(),
        };

        let response = self
            .client
            .post("https://api.openai.com/v1/embeddings")
            .header("Authorization", format!("Bearer {}", self.api_key))
            .header("Content-Type", "application/json")
            .json(&request)
            .send()
            .await?;

        // æ£€æŸ¥çŠ¶æ€ç 
        if !response.status().is_success() {
            let status = response.status();
            let error_text = response.text().await?;
            return Err(format!("API error ({}): {}", status, error_text).into());
        }

        // è§£æå“åº”
        let embedding_response: EmbeddingResponse = response.json().await?;

        // æå–å‘é‡ï¼ˆæŒ‰ index æ’åºï¼‰
        let mut embeddings_with_index: Vec<_> = embedding_response
            .data
            .into_iter()
            .map(|d| (d.index, d.embedding))
            .collect();
        embeddings_with_index.sort_by_key(|(idx, _)| *idx);

        let embeddings: Vec<Vec<f32>> = embeddings_with_index
            .into_iter()
            .map(|(_, emb)| emb)
            .collect();

        Ok((embeddings, embedding_response.usage.total_tokens))
    }

    /// è®¡ç®—ç¼“å­˜é”®ï¼ˆä½¿ç”¨ä»£ç çš„ hashï¼‰
    fn compute_cache_key(&self, text: &str) -> String {
        use std::collections::hash_map::DefaultHasher;
        use std::hash::{Hash, Hasher};

        let mut hasher = DefaultHasher::new();
        text.hash(&mut hasher);
        format!("{:x}", hasher.finish())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_compute_cache_key() {
        let client = EmbeddingsClient::new("test-key".to_string());
        let key1 = client.compute_cache_key("same text");
        let key2 = client.compute_cache_key("same text");
        let key3 = client.compute_cache_key("different text");

        assert_eq!(key1, key2);
        assert_ne!(key1, key3);
    }
}
