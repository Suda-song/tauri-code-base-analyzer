//! ä½¿ç”¨ç¤ºä¾‹
//!
//! æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä»£ç åˆ†å—å’Œå‘é‡åŒ–æ¨¡å—

#[cfg(test)]
mod tests {
    use crate::tool_execution::codebase::{ChunkBuilder, EmbeddingsClient, TypeScriptExtractor};

    /// ç¤ºä¾‹ 1: åŸºç¡€çš„ä»£ç åˆ†å—
    #[test]
    fn example_basic_chunking() {
        // 1. ä½¿ç”¨ TypeScriptExtractor æå–å®ä½“
        let mut extractor = TypeScriptExtractor::new(false).expect("åˆ›å»ºæå–å™¨å¤±è´¥");
        let test_file = "/Users/songdingan/dev/tauri-code-base-analyzer/src/test/after-sale-demo/src/api/afterSale.ts";
        let root_dir = "/Users/songdingan/dev/tauri-code-base-analyzer/src/test/after-sale-demo";

        let entities = extractor
            .extract(test_file, root_dir)
            .expect("æå–å®ä½“å¤±è´¥");
        println!("âœ… æå–åˆ° {} ä¸ªå®ä½“", entities.len());

        // 2. åˆ›å»º ChunkBuilder
        let builder = ChunkBuilder::new(root_dir.to_string());

        // 3. å°†å®ä½“è½¬æ¢ä¸º chunks
        let (chunks, stats) = builder.build_chunks(entities).expect("æ„å»º chunks å¤±è´¥");

        println!("\nğŸ“¦ ä»£ç å—ç»Ÿè®¡:");
        println!("  æ€»æ•°: {}", stats.total_chunks);
        println!("  æ€»ä»£ç é‡: {} å­—ç¬¦", stats.total_code_size);
        println!("  å¹³å‡å¤§å°: {} å­—ç¬¦", stats.avg_chunk_size);
        println!("  ç±»å‹åˆ†å¸ƒ: {:?}", stats.by_type);

        // 4. æŸ¥çœ‹ç¬¬ä¸€ä¸ª chunk çš„è¯¦ç»†ä¿¡æ¯
        if let Some(chunk) = chunks.first() {
            println!("\nğŸ“„ ç¬¬ä¸€ä¸ªä»£ç å—ç¤ºä¾‹:");
            println!("  ID: {}", chunk.id);
            println!("  ç±»å‹: {}", chunk.entity_type);
            println!("  æ–‡ä»¶: {}", chunk.relative_file);
            println!("  å¯¼å…¥: {:?}", chunk.imports);
            println!("  å¯¼å‡º: {:?}", chunk.exports);
            println!("  å¤æ‚åº¦: {}", chunk.complexity);
            println!("  æ˜¯å¦æµ‹è¯•: {}", chunk.is_test);
            println!("\n  Embedding æ–‡æœ¬é¢„è§ˆ:");
            let preview = chunk.embedding_text.chars().take(200).collect::<String>();
            println!("  {}", preview);
            if chunk.embedding_text.len() > 200 {
                println!("  ...(è¿˜æœ‰ {} å­—ç¬¦)", chunk.embedding_text.len() - 200);
            }
        }

        assert!(!chunks.is_empty());
    }

    /// ç¤ºä¾‹ 2: å®Œæ•´çš„å‘é‡åŒ–æµç¨‹ï¼ˆéœ€è¦ OpenAI API Keyï¼‰
    #[tokio::test]
    #[ignore] // é»˜è®¤å¿½ç•¥ï¼Œéœ€è¦æ‰‹åŠ¨è¿è¡Œ: cargo test example_full_workflow -- --ignored
    async fn example_full_workflow() {
        // ç¡®ä¿è®¾ç½®äº†ç¯å¢ƒå˜é‡
        let api_key = std::env::var("OPENAI_API_KEY").expect("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡");

        // 1. æå–å®ä½“
        let mut extractor = TypeScriptExtractor::new(false).unwrap();
        let test_file = "/Users/songdingan/dev/tauri-code-base-analyzer/src/test/after-sale-demo/src/api/afterSale.ts";
        let root_dir = "/Users/songdingan/dev/tauri-code-base-analyzer/src/test/after-sale-demo";

        let entities = extractor.extract(test_file, root_dir).unwrap();
        println!("ğŸ” æå–åˆ° {} ä¸ªå®ä½“", entities.len());

        // 2. æ„å»º chunks
        let builder = ChunkBuilder::new(root_dir.to_string());
        let (chunks, stats) = builder.build_chunks(entities).unwrap();
        println!("ğŸ“¦ ç”Ÿæˆäº† {} ä¸ªä»£ç å—", chunks.len());
        println!("ğŸ“Š å¹³å‡å¤§å°: {} å­—ç¬¦", stats.avg_chunk_size);

        // 3. å‘é‡åŒ–ï¼ˆåªå¤„ç†å‰ 3 ä¸ªä½œä¸ºç¤ºä¾‹ï¼‰
        let sample_chunks: Vec<_> = chunks.into_iter().take(3).collect();
        println!("\nğŸ§  å¼€å§‹å‘é‡åŒ– {} ä¸ªä»£ç å—...", sample_chunks.len());

        let mut embeddings_client = EmbeddingsClient::new(api_key);
        let (embedded_chunks, embed_stats) =
            embeddings_client.embed_chunks(sample_chunks).await.unwrap();

        // 4. æŸ¥çœ‹ç»“æœ
        println!("\nâœ… å‘é‡åŒ–å®Œæˆ!");
        println!("  æ€»æ•°: {}", embedded_chunks.len());
        println!("  å‘é‡ç»´åº¦: {}", embedded_chunks[0].embedding.len());
        println!("  æ€» tokens: {}", embed_stats.total_tokens);
        println!("  é¢„ä¼°æˆæœ¬: ${:.4}", embed_stats.estimated_cost);
        println!("  è€—æ—¶: {:.2}s", embed_stats.duration_secs);

        // 5. ä¿å­˜ç»“æœï¼ˆå¯é€‰ï¼‰
        let json = serde_json::to_string_pretty(&embedded_chunks).unwrap();
        std::fs::write("embedded_chunks_example.json", json).unwrap();
        println!("\nğŸ’¾ å·²ä¿å­˜åˆ° embedded_chunks_example.json");
    }

    /// ç¤ºä¾‹ 3: æµ‹è¯•ç¼“å­˜åŠŸèƒ½
    #[tokio::test]
    #[ignore]
    async fn example_caching() {
        let api_key = std::env::var("OPENAI_API_KEY").expect("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡");

        let mut extractor = TypeScriptExtractor::new(false).unwrap();
        let test_file = "/Users/songdingan/dev/tauri-code-base-analyzer/src/test/after-sale-demo/src/api/afterSale.ts";
        let root_dir = "/Users/songdingan/dev/tauri-code-base-analyzer/src/test/after-sale-demo";

        let entities = extractor.extract(test_file, root_dir).unwrap();
        let builder = ChunkBuilder::new(root_dir.to_string());
        let (chunks, _) = builder.build_chunks(entities).unwrap();

        let mut embeddings_client = EmbeddingsClient::new(api_key);

        // ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼ˆä¼šè°ƒç”¨ APIï¼‰
        println!("ğŸ§  ç¬¬ä¸€æ¬¡å‘é‡åŒ–...");
        let (_, stats1) = embeddings_client
            .embed_chunks(chunks.clone())
            .await
            .unwrap();

        println!("  API è°ƒç”¨: {}", stats1.api_calls);
        println!("  ç¼“å­˜å‘½ä¸­: {}", stats1.cache_hits);

        // ç¬¬äºŒæ¬¡è°ƒç”¨ï¼ˆåº”è¯¥å…¨éƒ¨å‘½ä¸­ç¼“å­˜ï¼‰
        println!("\nğŸ§  ç¬¬äºŒæ¬¡å‘é‡åŒ–ï¼ˆåº”è¯¥å‘½ä¸­ç¼“å­˜ï¼‰...");
        let (_, stats2) = embeddings_client
            .embed_chunks(chunks.clone())
            .await
            .unwrap();

        println!("  API è°ƒç”¨: {}", stats2.api_calls);
        println!("  ç¼“å­˜å‘½ä¸­: {}", stats2.cache_hits);

        assert_eq!(stats2.api_calls, 0, "ç¬¬äºŒæ¬¡è°ƒç”¨ä¸åº”è¯¥æœ‰ API è°ƒç”¨");
        assert_eq!(stats2.cache_hits, chunks.len(), "åº”è¯¥å…¨éƒ¨å‘½ä¸­ç¼“å­˜");
    }
}
